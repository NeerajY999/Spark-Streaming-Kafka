{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg9EGmpJchUT",
        "outputId": "9a66ce79-07a5-4667-fe49-85435b9ad4af"
      },
      "id": "Kg9EGmpJchUT",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=b2b524966824960db09086abb9a733ac6feee848e5efc495ac2e59e35f0cbf54\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "24b08f3e-4270-4a20-8946-10baf67bfafb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "24b08f3e-4270-4a20-8946-10baf67bfafb",
        "outputId": "dc03d77d-5f38-4623-ade0-d4b558c51924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2cbc2a2e30>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fd919527ff03:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Streaming from Kafka</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Create the Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Streaming from Kafka\") \\\n",
        "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \\\n",
        "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0') \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f943fa4-8a28-4d81-9c8f-b96f47ad032e",
      "metadata": {
        "id": "9f943fa4-8a28-4d81-9c8f-b96f47ad032e"
      },
      "outputs": [],
      "source": [
        "# Create the streaming_df to read from kafka\n",
        "df = spark.readStream\\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"telemetry-kafka-external-bootstrap-observability-kafka.apps.zagaopenshift.zagaopensource.com:443\") \\\n",
        "    .option(\"subscribe\", \"apmlogs\") \\\n",
        "    .option(\"startingOffsets\", \"earliest\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ccdf411a-602c-43d2-894d-8f61ba0bbabf",
      "metadata": {
        "id": "ccdf411a-602c-43d2-894d-8f61ba0bbabf"
      },
      "outputs": [],
      "source": [
        "df_parsed = df.selectExpr(\"CAST(value AS STRING) as json_string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "CvFvT8RufMXQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvFvT8RufMXQ",
        "outputId": "520e4001-2fe9-4c7a-f37c-713a2a1713cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[json_string: string]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f1942cef-d882-49d8-8286-1572baa02e02",
      "metadata": {
        "id": "f1942cef-d882-49d8-8286-1572baa02e02"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode, col, from_json\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, ArrayType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7fd41273-0208-4424-9c21-53b855069100",
      "metadata": {
        "id": "7fd41273-0208-4424-9c21-53b855069100"
      },
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField(\"resourceSpans\", ArrayType(StructType([\n",
        "        StructField(\"resource\", StructType([\n",
        "            StructField(\"attributes\", ArrayType(StructType([\n",
        "                StructField(\"key\", StringType()),\n",
        "                StructField(\"value\", StructType([\n",
        "                    StructField(\"stringValue\", StringType()),\n",
        "                    StructField(\"intValue\", IntegerType())\n",
        "                ]))\n",
        "            ])))\n",
        "        ])),\n",
        "        StructField(\"scopeSpans\", ArrayType(StructType([\n",
        "            StructField(\"scope\", StructType([\n",
        "                StructField(\"name\", StringType()),\n",
        "                StructField(\"version\", StringType())\n",
        "            ])),\n",
        "            StructField(\"spans\", ArrayType(StructType([\n",
        "                StructField(\"traceId\", StringType()),\n",
        "                StructField(\"spanId\", StringType()),\n",
        "                StructField(\"parentSpanId\", StringType()),\n",
        "                StructField(\"flags\", IntegerType()),\n",
        "                StructField(\"name\", StringType()),\n",
        "                StructField(\"kind\", IntegerType()),\n",
        "                StructField(\"startTimeUnixNano\", LongType()),\n",
        "                StructField(\"endTimeUnixNano\", LongType()),\n",
        "                StructField(\"attributes\", ArrayType(StructType([\n",
        "                    StructField(\"key\", StringType()),\n",
        "                    StructField(\"value\", StructType([\n",
        "                        StructField(\"stringValue\", StringType()),\n",
        "                        StructField(\"intValue\", IntegerType())\n",
        "                    ]))\n",
        "                ]))),\n",
        "                StructField(\"status\", StructType())\n",
        "            ])))\n",
        "        ]))),\n",
        "        StructField(\"schemaUrl\", StringType())\n",
        "    ])))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "97726e23-cb8a-4c14-9563-f045808ceb3e",
      "metadata": {
        "id": "97726e23-cb8a-4c14-9563-f045808ceb3e"
      },
      "outputs": [],
      "source": [
        "df_parsed = df_parsed.withColumn(\"data\", from_json(col(\"json_string\"), schema))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Fc3vbFs5f5h2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc3vbFs5f5h2",
        "outputId": "619628f4-33c8-427e-c7da-1ac318c9563a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[json_string: string, data: struct<resourceSpans:array<struct<resource:struct<attributes:array<struct<key:string,value:struct<stringValue:string,intValue:int>>>>,scopeSpans:array<struct<scope:struct<name:string,version:string>,spans:array<struct<traceId:string,spanId:string,parentSpanId:string,flags:int,name:string,kind:int,startTimeUnixNano:bigint,endTimeUnixNano:bigint,attributes:array<struct<key:string,value:struct<stringValue:string,intValue:int>>>,status:struct<>>>>>,schemaUrl:string>>>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "omfpRrhtgBE-",
      "metadata": {
        "id": "omfpRrhtgBE-"
      },
      "outputs": [],
      "source": [
        "query = df_parsed.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "szbUa8g_gD8q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szbUa8g_gD8q",
        "outputId": "7cee5c67-6112-4bf6-c25e-cdcf4caf1f4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.query.StreamingQuery at 0x7f2cbe609660>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cGUQXqOgeKZp",
      "metadata": {
        "id": "cGUQXqOgeKZp"
      },
      "outputs": [],
      "source": [
        "query.awaitTermination()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qIj3FHM0hJCX",
      "metadata": {
        "id": "qIj3FHM0hJCX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}